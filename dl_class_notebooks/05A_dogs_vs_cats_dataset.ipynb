{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dogs vs. Cats Dataset\n",
    "\n",
    "This dataset appears in Chollet, Deep Learing with Python 2nd edition, chapter 8 (book and associated notebook). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be obtained from:\n",
    "* [Dogs versus Cats](https://www.kaggle.com/c/dogs-vs-cats) - The Kaggle competition\n",
    "* [The Dataset](https://www.kaggle.com/datasets/biaiscience/dogs-vs-cats) (with an Open Data license)\n",
    "\n",
    "See the competition page for a nice introduction to the competition. Here is a description of the dataset taken from there:\n",
    "\n",
    "> ### The Asirra data set\n",
    ">Web services are often protected with a challenge that's supposed to be easy for people to solve, but difficult for computers. Such a challenge is often called a CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) or HIP (Human Interactive Proof). HIPs are used for many purposes, such as to reduce email and blog spam and prevent brute-force attacks on web site passwords.\n",
    "\n",
    ">Asirra (Animal Species Image Recognition for Restricting Access) is a HIP that works by asking users to identify photographs of cats and dogs. This task is difficult for computers, but studies have shown that people can accomplish it quickly and accurately. Many even think it's fun! Here is an example of the Asirra interface:\n",
    "\n",
    ">Asirra is unique because of its partnership with Petfinder.com, the world's largest site devoted to finding homes for homeless pets. They've provided Microsoft Research with over three million images of cats and dogs, manually classified by people at thousands of animal shelters across the United States. Kaggle is fortunate to offer a subset of this data for fun and research. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the dataset from Kaggle.\n",
    "2. Extract `train.zip` into a folder of your choice.  You should have **25,000** images, of about 600MB. The folder could be part of the repository, e.g.  `./data/kaggle_dogs_vs_cats/` . By the way, if you save it in the `./data/` folder it won't be tracked with Git, given that this folder appears in the `.gitignore` file. This is preferred, since `Git` and `Github` are not intended as data repositories.\n",
    "3. run the following code to create a small dataset of 1000 training images, 500 validation images and 1000 test images *per class*. This reduces the dataset from 25,000 images to 5000.\n",
    "4. You can manually delete the larger dataset as well as the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"../data/kaggle_dogs_vs_cats/train\")\n",
    "new_base_dir = pathlib.Path(\"../data/kaggle_dogs_vs_cats_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To the Student**: Explore the data:\n",
    "* Randmoly scroll through the images. Any notable insights from the perspective of training and testing? \n",
    "* What is the size in pixels of the images? \n",
    "* What color scheme (grayscale, RGB, other) are they coded in?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
