{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should point to the small dataset of the Kaggle Dogs vs Cats competition that was created in a previous notebook\n",
    "data_folder = pathlib.Path('../data/kaggle_dogs_vs_cats_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Image Data into a `Dataset` class for Training\n",
    "\n",
    "The Tensorflow `Dataset` class is TF's default method to load data. From its [docs]([Title](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)):\n",
    "\n",
    "> The tf.data.Dataset API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
    ">1. Create a source dataset from your input data.\n",
    ">2. Apply dataset transformations to preprocess the data.\n",
    ">3. Iterate over the dataset and process the elements.\n",
    "\n",
    ">Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.\n",
    "\n",
    "To read more about the `Dataset` class, see Tensorflow's [Data Guide](https://www.tensorflow.org/guide/data) and [Data Performance Guide](https://www.tensorflow.org/guide/data_performance).\n",
    "\n",
    "Keras offers several utility functions to load data into TF's `Dataset` class. **See Keras [docs]([Title](https://keras.io/api/data_loading/)) for a list of all the data types that it can load**. One such utility function is the  `image_dataset_from_directory` that we use here. Note that there are additional ways to image data (see [tutorial]([Title](https://www.tensorflow.org/tutorials/load_data/images)))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Dataset` class\n",
    "Before we go into loading images, let's take a look at the `Dataset` class. It acts like a Python iterator, in which in each call it provides data for either training or evaluation. The data can be a single data sample, or a batch Tensorflow optimizes the performance of the data load, and covers the whole data set per epoch during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a data as a `NumPy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_numbers = np.random.normal(size=(1000, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1000, 16)\n",
      "float64\n",
      "[[ 0.28163258 -0.46810717  0.12479456  1.27036153  0.99383731  1.20054864\n",
      "  -0.00316159 -0.30338952  0.89201479 -0.95646887  0.0287871  -0.2557161\n",
      "  -0.73116838  0.40990051 -0.14357482  0.03638614]\n",
      " [ 0.31092888 -0.5429373  -0.52020321  1.15555237  0.66089029  1.24451936\n",
      "   0.1914797   0.40182437 -0.05717869 -1.10696724  0.92676361  0.79312175\n",
      "  -0.94112144 -0.61725669 -0.82011052 -0.25030754]\n",
      " [-0.68873302 -1.49687682 -0.4459783   2.54131492 -1.53784571 -0.32989175\n",
      "   0.11651781 -0.32314156 -1.00848958 -0.95996169  0.66446594 -0.71444421\n",
      "   1.8433425  -1.20494051  0.37084589  0.31745678]\n",
      " [ 0.54387202  1.95881492  0.14069934 -0.14561345 -0.75947224 -1.35716761\n",
      "   0.23288172  1.80303935  0.4051701   1.16463857  1.04769526 -0.17474879\n",
      "  -0.78197064  0.43326643  1.15578448  0.37671455]]\n"
     ]
    }
   ],
   "source": [
    "print(type(random_numbers))\n",
    "print(random_numbers.shape)\n",
    "print(random_numbers.dtype)\n",
    "print(random_numbers[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using the method `from_tensor_slices` we define a `Dataset` instance: \n",
    "\n",
    "The tensor is sliced along its first dimension, with each slice being of a single index of the first dimension\n",
    "[docs](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n",
      "(16,)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.28163258 -0.46810717  0.12479456  1.27036153  0.99383731  1.20054864\n",
      " -0.00316159 -0.30338952  0.89201479 -0.95646887  0.0287871  -0.2557161\n",
      " -0.73116838  0.40990051 -0.14357482  0.03638614], shape=(16,), dtype=float64)\n",
      "tf.Tensor(\n",
      "[ 0.31092888 -0.5429373  -0.52020321  1.15555237  0.66089029  1.24451936\n",
      "  0.1914797   0.40182437 -0.05717869 -1.10696724  0.92676361  0.79312175\n",
      " -0.94112144 -0.61725669 -0.82011052 -0.25030754], shape=(16,), dtype=float64)\n",
      "tf.Tensor(\n",
      "[-0.68873302 -1.49687682 -0.4459783   2.54131492 -1.53784571 -0.32989175\n",
      "  0.11651781 -0.32314156 -1.00848958 -0.95996169  0.66446594 -0.71444421\n",
      "  1.8433425  -1.20494051  0.37084589  0.31745678], shape=(16,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(dataset):\n",
    "    print(element)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this `Dataset`, we can define a `BatchDataset` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 16)\n",
      "(32, 16)\n",
      "(32, 16)\n"
     ]
    }
   ],
   "source": [
    "batched_dataset = dataset.batch(32)\n",
    "for i, element in enumerate(batched_dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here every batch has 32 samples, each with 16 elements (floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.batch_op._BatchDataset"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batched_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras Utility Functions to Create a `Dataset` for Images\n",
    "Keras offers a utility class, `image_dataset_from_directory`, that loads images into a `Dataset` class.\n",
    "\n",
    "**To the Student**: According to the [docs](https://keras.io/api/data_loading/image/) of `image_dataset_from_directory`:\n",
    "* What folder structure does `image_dataset_from_directory` expect? \n",
    "* What is the output of `image_dataset_from_directory`?\n",
    "* What is the function of the `image_size` argument?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.batch_op._BatchDataset"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the shapes of the data and labels yielded by the `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (32, 180, 180, 3)\n",
      "labels batch shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_dataset:\n",
    "    print(\"data batch shape:\", data_batch.shape)\n",
    "    print(\"labels batch shape:\", labels_batch.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "tensorflow_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
